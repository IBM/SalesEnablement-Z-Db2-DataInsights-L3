{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Introduction","text":""},{"location":"#ai-at-scale-on-ibm-z-using-db2-for-zos-sql-data-insights","title":"AI at scale on IBM Z using Db2 for z/OS SQL Data Insights","text":""},{"location":"#demonstration-using-ibm-virtual-development-and-test-for-zos-db2-for-zos-v13-with-sql-data-insights","title":"Demonstration using IBM Virtual Development and Test for z/OS, Db2 for z/OS V13 with SQL Data Insights.","text":""},{"location":"#gain-more-data-insights-with-ai-enabled-query-in-db2-for-zos","title":"Gain more data insights with AI-Enabled query in Db2 for z/OS","text":"<p>Prerequisites</p> <p>Before undertaking this lab, you are expected to understand:</p> <ul> <li>Db2 for z/OS</li> <li>The SQL language</li> <li>Artificial Intelligence (AI) concepts</li> <li>Machine Learning and Deep Learning model concepts</li> </ul> <p>Artificial Intelligence (AI) has become an essential capability for enterprises to exploit and master. The data that is stored and managed in operational databases contains information that is invaluable to making informed decisions. Sometimes the insights can be extracted using conventional Structured Query Language (SQL) queries. But when the information clients seek is hidden in non-obvious patterns in the data, conventional SQL is not flexible enough to see those patterns.</p> <p>Db2 for z/OS SQL Data Insights is a transformational technology, that enables Deep Learning AI models to be trained against mainframe data, so that anybody who writes SQL queries can invoke standard SQL functions to understand the data patterns without any need for data science expertise. Db2 for z/OS SQL Data Insights is also called SQL Data Insights through this document.</p> <p>The illustration below represents how Db2 for z/OS SQL Data Insights would be used.</p> <ul> <li>The Clients table holds information about the clients of a business.</li> <li>The related model table is created when SQL Data Insights is instructed to Enable AI.</li> <li>The example SQL query aims to find the top 20 clients who are most similar to the client with customer ID of 3668-QPYBK. The client in question may be of interest because of good or bad outcomes to be encouraged or avoided in other clients.</li> <li>The first version of SQL Data Insights (DB2 13 FL500) provides 3 built-in functions: <code>AI_SIMILARITY</code>, <code>AI_SEMANTIC_CLUSTER</code>, and <code>AI_ANALOGY</code>. All AI functions are based on the unsupervised neural network model that has been trained to find natural patterns in the data. In the case of the <code>AI_SIMILARITY</code> function, it computes a similarity score between any two records in an AI-enabled table.</li> <li>SQL queries can be submitted from anywhere with a SQL connection to Db2.</li> </ul> <p></p> <p>This demonstration will be focused on the steps that the Database Administrator takes to Enable AI against Db2 tables and views, and the SQL query patterns that business users need to adopt to perform AI-Enabled queries.</p> <p>This use case applies to IBM clients that have the following environment:</p> <p>Mandatory</p> <ul> <li>They are running Db2 for z/OS V13 Function Level 500 or later.</li> <li>They must have installed the optional SQL Data Insights feature of Db2.</li> </ul> <p>Nice to have</p> <ul> <li>The subject data should include as many features as possible that describe the characteristics of the entity (for example: Client) being studied.</li> <li>Ideally, good or bad outcomes labels are included within the data, to provide a focus for AI enabled queries to use.</li> <li>Model training with SQL Data Insights is CPU-intensive but is almost totally zIntegrated Information Processor (zIIP) eligible. Available zIIP engines for model training help to avoid unwanted general processor CPU consumption.</li> </ul> <p>Other considerations to be evaluated</p> <ul> <li>Operational databases tend to store data in multiple different tables, such as with third normal form data models. The objective of such data structures is to separate data into different entities (tables) for flexibility. This is the opposite of what is wanted for machine learning. Clients should consider using SQL views to join data from multiple tables to include all the data fields that are of interest in AI-enabled analysis.</li> <li>Data stored outside Db2 for z/OS can also be used by SQL Data Insights. For example, data in Virtual Storage Access Method (VSAM) datasets or Information Management System (IMS) databases can be references in Db2 table functions, so that they too can be AI-Enabled.</li> </ul>"},{"location":"Resources/","title":"Additional resources","text":"<p>Explore these resources to learn more.</p> <ul> <li> <p>Demonstration video: IBM Db2 SQL Data Insights - Uncover insights based on hidden relationships in Db2 for z/OS data</p> </li> <li> <p>Articles about SQL Data Insights:</p> <ul> <li>Use IBM Db2 SQL Data Insights to uncover hidden relationships in your data </li> <li>Db2 SQL Data Insights: Discover hidden insights within your Db2 Data</li> </ul> </li> <li> <p>Db2 Documentation: </p> <ul> <li>Db2 13 for z/OS</li> <li>Enabling Db2 for IBM Db2 Analytics Accelerator for z/OS</li> </ul> </li> </ul>"},{"location":"setupEnv/","title":"Setup the environment","text":"<p>The IBM Z Virtual Access (zVA) image was provided with a SQL Data Insights instance deployed, and the Db2 tables trained. If your zVA system has been freshly provisioned, and you wish to perform the SQL Data Insights Level 3 hands on learning (as covered in this document), there is no setup to perform. Just go to the Overview \u2013 What is covered in the workbook section of this document and work down from there.</p>"},{"location":"test/","title":"Test file","text":"<p>Test file for markdown</p>"},{"location":"test/#-switch-user-lorem-ipsum-dolor-sit-amet-1-consectetur-adipiscing-elit","title":"- Switch user Lorem ipsum dolor sit amet, (1) consectetur adipiscing elit.","text":"<ul> <li> <ol> <li>:man_raising_hand: I'm an annotation! I can contain <code>code</code>, formatted text, images, ... basically anything that can be expressed in Markdown.</li> </ol>"},{"location":"BA/Develop/","title":"Develop SQL queries to address these requirements","text":"<p>To be written....</p>"},{"location":"BA/Review/","title":"Review the business data insights requirements","text":"<p>To be written....</p>"},{"location":"DBA/ManageDIS/","title":"Manage the SQL Data Insights Service","text":"<p>Follow the directions below to manage the SQL Data Insights service.</p> <ul> <li> <p>In the virtual environment, open the Google Chrome (A) browser and enter the URL (B) for the SQL Data Insights web interface:</p> <pre><code>https://wg31.washington.ibm.com:15001/\n</code></pre> <p></p> </li> <li> <p>If you see a \"Your connection is not private\" message, click Advanced (A) and then clink the Proceed link (B) to open the unencrypted connection.</p> <p></p> <p></p> </li> <li> <p>Log into SQL Data Insights using user (A):</p> <pre><code>IBMUSER\n</code></pre> <p>and password (B):</p> <pre><code>SYS1\n</code></pre> <p>and then click Sign in (C).</p> <p></p> </li> <li> <p>SQL Data Insights has already been configured to access Db2 for z/OS. You will be connecting to a subsystem with SSID=DBDG and LocationName=DALLASD. Click the ellipses () at the right-hand side of the DBDG connection (A), and click Connect (B) from the dropdown menu.</p> <p></p> </li> <li> <p>Use the same Resource Access Control Facility (RACF) credentials as before to connect to the DBDG subsystem. Enter the user ID (A):</p> <pre><code>IBMUSER\n</code></pre> <p>and password (B):</p> <pre><code>SYS1\n</code></pre> <p>and then click Connect (C).</p> <p></p> </li> </ul> <p>In this demonstration you will be using 3 Db2 tables.</p> <code>DSNAIDB.CHURN</code> <p>A dataset from a telecommunications company (telco) containing 7,043 customer records, of which 1,869 have cancelled their contracts (Churn = Yes).</p> <code>EXPLORE.PENGUINS</code> <p>A classic data science dataset which is used as a sample dataset for learning data science. The challenge is to use several penguin measurements (weight, height, length, location, etc) to build a classification model to determine what species they are.</p> <code>EXPLORE.PENGUINS_UNC</code> <p>A view of the PENGUINS table that excludes the answer (the species).</p> <p>About the penguins dataset</p> <p>The penguins dataset is well covered in a number of data science websites, including Palmer Archipelago (Antarctica) penguin data.</p> <ul> <li> <p>Display all the Db2 tables and views that have already been enabled for AI. Click the ellipses () (A) and then click List AI objects (B).</p> <p></p> </li> </ul> <p>The list of AI-enabled objects is displayed. This is the administration web page where you can work with AI-enabled objects and select new objects to train.</p> <p></p> <ul> <li> <p>Click Add object (A) to invoke the dialog to train a new Db2 table or view.</p> <p></p> </li> <li> <p>Select the EXPLORE schema to filter by (B) and click the magnifying glass icon () (C) to list the objects in that schema.</p> <p></p> </li> </ul> <ul> <li> <p>From the generated list, select the PENGUINS_UNC table (A) (1) and then click Enable AI query (B).</p> <p></p> </li> </ul> <ol> <li>This is a table with measurements of various penguins in a scientific study in Antarctica, without the species classification field (penguins unclassified). It would be cheating to include the classification field, because you want to assess how well SQL Data Insights can address the classification challenge without any formal data science expertise, and without using the answer.</li> </ol> <ul> <li> <p>Review each of the fields in the table. First, checkmark all column names (A). Next, you need to tell the SQL Data Insights model training process how to treat each field, according to the available data types: categorical, numerical, and key. Generally string data types should be treated as categorical fields, and numeric data types should be treated as numeric fields. Exception: numeric fields should be defined as categorial if they have a categorial meaning (for example phone numbers, postal codes, etc.), but this is not relevant for this demonstration. Change the ID field to the Key data type (B). Click Next (C).</p> <p></p> </li> <li> <p>Optionally, you can tell SQL Data Insights what values to treat as NULL values and exclude from the model training process. The penguins\u2019 data has very few null values, so you will skip this step and click Enable (A).</p> <p></p> </li> </ul> <p>The SQL Data Insights user interface will return to the AI objects panel. The PENGUINS_UNC table shows a status of Training.</p> <p></p> <p>SQL Data Insights is designed to be simple to use and there is tooling available to monitor its progress. The model training process uses an embedded Spark cluster to train the model. The Spark cluster provides a browser dashboard to monitor the status of Spark nodes, training jobs in progress, and completed training jobs. Training jobs are displayed with hyperlinks to access execution logs if needed.</p> <ul> <li> <p>Open a new tab in the Google Chrome browser and enter the following URL (A) to open the Spark dashboard: </p> <pre><code>http://wg31.washington.ibm.com:8080\n</code></pre> <p></p> </li> <li> <p>Return to the SQL Data Insights tab and verify the table is now Enabled. You may need to refresh (A) the web page.</p> <p></p> </li> <li> <p>Review the summary details of the trained models. Click the ellipses () next to the PENGUINS_UNC table (A) and click Analyze data (B).</p> <p> </p> </li> </ul> <p>Click each of the four tabs to review the model details.</p> <code>Object details</code> <p>The Object details report (A) provides information about the features in the dataset.</p> <p></p> <code>Data statistics</code> <p>The Data statistics report (A) is a collection of statistical analysis values of the data.</p> <p></p> <code>Column influence</code> <p>The Column influence report (A) shows which features in the dataset were completed. Some of the penguins were not weighed or sexed.</p> <p></p> <code>Colukmn discriminator</code> <p>The Column discriminator report (A) is derived from the neural network model that has been built and shows how significant the values of a column are in semantically distinguishing between different records.</p> <p></p>"},{"location":"DBA/StartDIS/","title":"Start the SQL Data Insights Service","text":"<p>When instructions are given to type text, the text is usually like below:</p> <pre><code>Sample text to enter.\n</code></pre> <p>This is to help indicate that you need to type or copy/paste all of the text. Notice the Copy to clipboard button (). Use it to copy the text and then use your system's paste option (Cmd+V or Ctrl+V) to enter the text.</p> <p>Follow the directions below to start the SQL Data Insights service.</p> <ul> <li> <p>Open the Putty terminal, by clicking on the proper desktop icon (A).</p> <p> </p> </li> <li> <p>Highlight the saved session called wg31_large (A), and click Load (B). Click Open (C) to open a ssh terminal session to the z/OS host: wg31.</p> <p></p> </li> <li> <p>Login with user (A):</p> <p></p><pre><code>IBMUSER\n</code></pre> and password (B): <pre><code>SYS1\n</code></pre> <p></p> </li> </ul> <ul> <li> <p>Switch user to AIDBADM (1) using the su command (A):</p> <pre><code>su - adibadm\n</code></pre> <p>and enter the password (B):</p> <pre><code>AIDBADM\n</code></pre> <p></p> </li> </ul> <ol> <li>AIDBADM is the instance owner of the SQL Data Insights instance.</li> </ol> <ul> <li> <p>Stat the SQL Data Insights instance using the command below (A):</p> <pre><code>sqldi.sh start\n</code></pre> <p></p> <p>The SQL Data Insights Services runs under Unix System Services (USS), which is why you have started it from the USS command line. It can easily be wrapped in a JCL member and run as a started task with system automation.</p> </li> </ul>"},{"location":"DBA/VerifyDIS/","title":"Verify the trained model with simple SQL queries","text":"<p>You can use any SQL client tool you like to write SQL queries that use SQL Data Insights. For example, when using a 3270 emulator you could use SQL Processor Using File Input (SPUFI) (1) or Query Management Facility (QMF) (2). Alternatively, from a Windows client you could use a developer Integrated Development Environment (IDE), or an analytics tool like QMF workstation.</p> <ol> <li>SPUFI is a database facility invented by IBM for interfacing with their Db2 system. It is accessed from within TSO ISPF from the DB2I Primary Option menu. SPUFI allows direct input of SQL commands in the TSO environment, rather than having them embedded within a program. Learn more about SPUFI here.</li> <li>QMF is a security-rich, simple-to-use business analytics and visualization tool optimized for IBM Z\u00ae data sources. Learn more about QMF here.</li> </ol> <p>Since you are exploiting AI capabilities, it seems appropriate to use tools that are commonly used by data scientists. After all, one of the use cases for SQL Data Insights is to aid the data scientist perform data analysis (or data wrangling).</p> <p>The Windows image of this demonstration has been pre-installed with Anaconda, Python, Jupyter Notebooks, and several data science libraries. You will invoke Jupyter Notebooks from Microsoft Visual Studio (VS) Code, to build your SQL queries.</p> <ul> <li> <p>Click the Visual Studio Code desktop icon (A) to open VS Code.</p> <p></p> </li> <li> <p>Open the Notebook named SQL_Data_Insights.ipynb if not already open. Click File (A), then click Open File (B), then click SQL_Data_Insights.ipynb (C), and then click Open (D).</p> <p></p> </li> </ul> <p>Once the Notebook renders in VS, you may want to adjust the settings as follows.</p> <ul> <li>Use Ctrl+- or Ctrl++ to adjust the font size of all panels in the display.</li> </ul> <ul> <li> <p>Verify the Python kernel cw01 loaded (A) (1). If needed (or if prompted), click Restart (B) to restart the kernel (2).</p> <p></p> </li> </ul> <ol> <li>This demonstration environment has no internet connectivity, and the cw01 kernel has all the libraries needed for this demonstration. They were previously installed so that you can run the notebooks.</li> <li>To start the notebook from scratch click Restart again to clear all outputs.</li> </ol> <p>Next, run each step of the Jupyter notebook to connect to the data base and execute SQL statements.</p> <p>To run a Jupyter notebook step</p> <p>To run the instructions in a cell, you highlight the cell (a blue line will appear to the left of the cell) and click the arrow (A) to invoke the code in that cell or use the keyboard shortcut: Ctrl+Alt+Enter.</p> <p></p> <p>The notebook advises to train the model, but this has already been done. You don\u2019t need to perform this step again. </p> <p>The first cell does not need to be run because the libraries were installed before the system was disconnected to the internet. If you execute this cell, it should tell you that all libraries were already satisfied. These are the libraries used: Python, \"connect to Db2\", and \"format SQL results sets from Db2 nicely\".</p> <ul> <li> <p>Run the two cells used to import environment variables and libraries into the Python environment (A).</p> <p></p> </li> </ul> <ul> <li> <p>Run the next two cells to load the SQL extension (from the sqlalchemy package) (A) and to establish a JDBC type 4 connection to Db2 on z/OS (B) (1).</p> <p></p> </li> </ul> <ol> <li>The Db2 subsystem being used is a location name of DALLASD running on wg31.washington.ibm.com on port 5045. You are connecting with user ID IBMUSER and password SYS1.</li> </ol> <p>Now you are ready to run SQL queries against the Db2 instance. Start with a simple SQL Select against the EXPLORE.PENGUINS table.</p> <ul> <li> <p>Run the cell with the SQL select command (A).</p> <p></p> </li> </ul> <p>The Penguin dataset represents a data science classification challenge. Based on several observations, is it possible to accurately predict what species any penguin is? The output shown above contains the answer.</p> <p>To validate the ability of SQL Data Insights to find similarities and differences between records, you need to create a view that excludes the answers. Thus, why the EXPLORE.PENGUINS_UNC view was created and trained in the previous steps.</p> <ul> <li> <p>Run the SQL select against the explore.penguins_unc view (A).</p> <p></p> </li> </ul> <p>Now, perform an SQL query to test that one of the SQL Data Insights built in functions can be invoked successfully against the PENGUINS_UNC table that has an associated trained model.</p> <ul> <li> <p>Run the AI_SIMILARITY SQL select against the explore.penguins_unc view (A)**.</p> <p></p> </li> </ul> <p>Review the results!</p> <p>The SQL query uses the AI_SIMILARITY function to measure the similarity of Penguin #11 to all other penguins in the dataset. At this point you are not trying to assess the accuracy of the SQL Data Insights model; rather, you are merely verifying that the model table has been trained and can be utilized by the SQL Data Insights built in SQL functions.</p> <p>The result set returns all the columns from the PENGUINS_UNC table, plus an additional column (similarity) which is the similarity of each penguin with Penguin #11.</p> <p>Note that this similarity score is not an absolute score or probability. It is a determination of the similarity of two records based on the unsupervised Deep Learning model that was trained by SQL Data Insights. When you write SQL queries you need to develop a feel for what that means in practical terms by designing your AI-enabled queries accordingly.</p> <p>It would be good to perform some sort of accuracy check to check whether SQL Data Insights has done a good job of discovering the patterns in the penguin data measurements. You have the means to do that because you have the original dataset that included the species as determined by the Antarctic scientists who took all the measurements of the penguins in the first place.</p> <p>Penguin #11 was determined to be an Adelie Penguin.</p> <ul> <li>Penguins with IDs from 1 to 152 were Adelie Penguins.</li> <li>Penguins with IDs from 153 to 276 were Gentoo Penguins.</li> <li>Penguins with IDs from 277 to 344 were Chinstrap Penguins.</li> </ul> <p>You can write SQL queries to select: - the average similarity of Penguin #11 to all other Adelie penguins - the average similarity of Penguin #11 to all Gentoo penguins - the average similarity of Penguin #11 to all Chinstrap penguins</p> <ul> <li> <p>Run the SQL query to select the average similarity of Penguin #11 to all other Adelie penguins (A) (1).</p> <p></p> <p>The result (which may vary slightly when you train the model) shows a value like this:</p> <p></p> </li> </ul> <ol> <li>SQL query    <code>%sql with V1 as (SELECT U.*, decimal(AI_SIMILARITY(ID,11),5,2) AS SIMILARITY FROM EXPLORE.PENGUINS_UNC U WHERE U.ID between 1 and 152 ) select AVG(similarity) from V1 ;</code></li> </ol> <ul> <li> <p>Run the SQL query to select the average similarity of Penguin #11 to all all Gentoo penguins (A) (1).</p> <p></p> <p>The result shows a value like this:</p> <p></p> </li> </ul> <ol> <li>SQL query    <code>.sql %sql with V1 as (SELECT U.*, decimal(AI_SIMILARITY(ID,11),5,2) AS SIMILARITY FROM EXPLORE.PENGUINS_UNC U WHERE U.ID between 153 and 276 ) select AVG(similarity) from V1 ;</code></li> </ol>  - Run the SQL query to select the average similarity of Penguin #11 to all all Chinstrap penguins **(A)** (1).      ![](_attachments/vsSQL-11-Chinstrap.jpg)      The result shows a value *like* this:      ![](_attachments/vsSQL-11-ChinstrapResult.jpg)   <ol> <li>SQL query    <code>.sql %sql with V1 as (SELECT U.*, decimal(AI_SIMILARITY(ID,11),5,2) AS SIMILARITY FROM EXPLORE.PENGUINS_UNC U WHERE U.ID between 277 and 344 ) select AVG(similarity) from V1 ;</code></li> </ol> <p>The first query shows a similarity much higher than the others two queries. There are some additional queries that you can run in the Jupyter notebook for additional information and testing.</p> <p>Pause and reflect on what SQL Data Insights has just done. With absolutely zero data science skills and zero knowledge of the anatomy of penguins, SQL Data Insights can clearly differentiate between the species of penguin. It does this purely based on values, with no contextual reference frame in a Db2 table.</p> <p>If SQL Data Insights can classify records from a classical data science dataset, then it can do the same for business-oriented datasets!</p>"},{"location":"Overview/ReserveEnv/","title":"Reserve the demonstration environment","text":"<p>Before you start, reserve the demo environment using this link. Demo reservations should be submitted 2 days in advance. The reservation is accessible for up to 4 days.</p> <ul> <li> <p>For IBMers: </p> <p>Log in with your w3ID and VPN if working remotely to access and select Request virtual access. Expand and select the GA IBM DB2 SQL Data Insight z/OS Workshop (A) and click Select (B). Then click Next (C) and complete the form to request demo access.</p> <p></p> <p>You will receive an email when your demo environment is ready with access credentials.</p> </li> <li> <p>For Business Partners:</p> <p>Contact your IBM Business Partner Representative for environment access.</p> </li> </ul>"},{"location":"Overview/UsingSQL/","title":"Using SQL Data Insights to execute AI-enabled SQL queries scenario","text":"<p>The image below depicts the high-level architecture used in this demonstration environment.</p> <p></p> <p>In this demonstration scenario, the client\u2019s operational data is stored in Db2 for z/OS, and they wish to take advantage of machine learning techniques to gain better insights into their customer\u2019s needs by learning from patterns in the data that they already possess. They plan to develop predictive models in due course to assist with customer care and the point of interaction, but they wish to start by using AI to gain better insights into their customers\u2019 patterns of activities. You will demonstrate how SQL Data Insights builds an unsupervised Deep Learning model of the clients\u2019 data, so that they may perform simple SQL analysis to take advantage of AI insights for the analytics phase of their journey to AI.</p> <p>In this demonstration you will be using a Db2 dataset from a telecommunications company (telco), containing 7,043 customer records, of which 1,869 have cancelled their contracts (Churn = Yes). Clients that have a lot of churn going on, may want to identify patterns in the data for customers that haven't yet canceled their accounts, to try retaining them.</p> <p>Another dataset, the penguin dataset, which is used as a sample dataset for learning data science, will also be used, where the challenge is to use several penguin measurements to build a classification model to determine what species they are. This dataset will be used to validate the ability of SQL Data Insights in finding similarities and differences between records.</p>"},{"location":"Overview/UsingSQL/#tasks","title":"Tasks","text":"<p>Database Administrator persona</p> <ul> <li>Manage the SQL Data Insights Service and enable AI for selected Db2 tables and views.</li> <li>Verify the trained SQL Data Insights model with SQL queries.</li> </ul> <p>Business Analyst persona</p> <ul> <li>Refine business data insights requirements.</li> <li>Develop SQL queries to address those requirements.</li> </ul>"},{"location":"Overview/ZVA/","title":"How to log into Z Virtual Access (zVA)","text":"<p>Follow these steps to when your reservation is ready.</p> <ul> <li> <p>When your IBM Z Virtual Access (zVA) reservation is ready you will receive an email from IBM Z Trail (ztrail@uk.ibm.com) (A) with a link to sign in to IBM Z Virtual Access. In the e-mail, click the IBM Z Virtual Access (B) hyperlink.</p> <p></p> </li> <li> <p>Select the Access details tab (A). Take note of the User for web access point and Password provided on this tab (B). Then click the link on the Web access point box (C). The IBM Z Trail login window opens. Enter the User for web access point and Password (from the previous screen) into the Username and Password fields (D) and click Sign in (E).</p> <p></p> </li> </ul>"}]}